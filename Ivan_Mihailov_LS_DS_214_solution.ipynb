{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ivan Mihailov LS_DS_214_solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivan-mihailov/LS-Unit-2-Sprint-1-Assignments/blob/main/Ivan_Mihailov_LS_DS_214_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaYlRc5g0YVr"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKnplpmf0YV2"
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsS9hU3h0YV4"
      },
      "source": [
        "# Module Project: Logistic Regression\n",
        "\n",
        "Do you like burritos? ðŸŒ¯ You're in luck then, because in this project you'll create a model to predict whether a burrito is `'Great'`.\n",
        "\n",
        "The dataset for this assignment comes from [Scott Cole](https://srcole.github.io/100burritos/), a San Diego-based data scientist and burrito enthusiast. \n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are the following:\n",
        "\n",
        "- **Task 1:** Import `csv` file using `wrangle` function.\n",
        "- **Task 2:** Conduct exploratory data analysis (EDA), and modify `wrangle` function .\n",
        "- **Task 3:** Split data into feature matrix `X` and target vector `y`.\n",
        "- **Task 4:** Split feature matrix `X` and target vector `y` into training and test sets.\n",
        "- **Task 5:** Establish the baseline accuracy score for your dataset.\n",
        "- **Task 6:** Build `model_logr` using a pipeline that includes three transfomers and `LogisticRegression` predictor. Train model on `X_train` and `X_test`.\n",
        "- **Task 7:** Calculate the training and test accuracy score for your model.\n",
        "- **Task 8:** Create a horizontal bar chart showing the 10 most influencial features for your  model. \n",
        "- **Task 9:** Demonstrate and explain the differences between `model_lr.predict()` and `model_lr.predict_proba()`.\n",
        "\n",
        "**Note** \n",
        "\n",
        "You should limit yourself to the following libraries:\n",
        "\n",
        "- `category_encoders`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `sklearn`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h7XHx7i0YV5"
      },
      "source": [
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRVPfbi_0YV5"
      },
      "source": [
        "def wrangle(filepath):\n",
        "    # Import w/ DateTimeIndex\n",
        "    df = pd.read_csv(filepath, parse_dates=['Date'],\n",
        "                     index_col='Date')\n",
        "    \n",
        "    # Drop unrated burritos\n",
        "    df.dropna(subset=['overall'], inplace=True)\n",
        "    \n",
        "    # Derive binary classification target:\n",
        "    # We define a 'Great' burrito as having an\n",
        "    # overall rating of 4 or higher, on a 5 point scale\n",
        "    df['Great'] = (df['overall'] >= 4).astype(int)\n",
        "    \n",
        "    # Drop high cardinality categoricals\n",
        "    df = df.drop(columns=['Notes', 'Location', 'Address', 'URL', 'Neighborhood'])\n",
        "    \n",
        "    # Drop columns to prevent \"leakage\"\n",
        "    df = df.drop(columns=['Rec', 'overall'])\n",
        "\n",
        "    # Drop columns with too many NaNs\n",
        "    df = df.drop(columns=['Yelp', 'Google',\t'Chips', 'Mass (g)',\t'Density (g/mL)',\t\n",
        "                          'Unreliable',\t'NonSD',\t'Chicken',\t'Shrimp', 'Fish',\n",
        "                          'Rice',\t'Beans',\t'Lettuce',\t'Tomato', 'Bell peper',\t\n",
        "                          'Carrots', 'Cabbage',\t'Sauce',\t'Salsa.1','Cilantro',\t\n",
        "                          'Onion',\t'Taquito',\t'Pineapple',\t'Ham', 'Chile relleno',\n",
        "                          'Nopales',\t'Lobster',\t'Queso',\t'Egg', 'Mushroom',\n",
        "                          'Bacon',\t'Sushi',\t'Avocado',\t'Corn',\t'Zucchini', 'Reviewer'])\n",
        "    \n",
        "    # Replace 'x' and 'X' in ingredient columns with '1'\n",
        "\n",
        "    df['Beef'] = df['Beef'].replace(['x', 'X'], 1)\n",
        "    df['Pico'] = df['Pico'].replace(['x', 'X'], 1)\n",
        "    df['Guac'] = df['Guac'].replace(['x', 'X'], 1)\n",
        "    df['Cheese'] = df['Cheese'].replace(['x', 'X'], 1)\n",
        "    df['Fries'] = df['Fries'].replace(['x', 'X'], 1)\n",
        "    df['Sour cream'] = df['Sour cream'].replace(['x', 'X'], 1)\n",
        "    df['Pork'] = df['Pork'].replace(['x', 'X'], 1)\n",
        "\n",
        "    # Replace NaNs in ingredient columns with '0'\n",
        "\n",
        "    df['Beef'] = df['Beef'].fillna(0) \n",
        "    df['Pico'] = df['Pico'].fillna(0)\n",
        "    df['Guac'] = df['Guac'].fillna(0)\n",
        "    df['Cheese'] = df['Cheese'].fillna(0)\n",
        "    df['Fries'] = df['Fries'].fillna(0)\n",
        "    df['Sour cream'] = df['Sour cream'].fillna(0)\n",
        "    df['Pork'] = df['Pork'].fillna(0)\n",
        "\n",
        "    # Convert ingredient columns to integer\n",
        "\n",
        "    df['Beef'] = df['Beef'].astype(int)\n",
        "    df['Pico'] = df['Pico'].astype(int)\n",
        "    df['Guac'] = df['Guac'].astype(int)\n",
        "    df['Cheese'] = df['Cheese'].astype(int)\n",
        "    df['Fries'] = df['Fries'].astype(int)\n",
        "    df['Sour cream'] = df['Sour cream'].astype(int)\n",
        "    df['Pork'] = df['Pork'].astype(int)\n",
        "    \n",
        "    return df\n",
        "\n",
        "filepath = DATA_PATH + 'burritos/burritos.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_9VIkX-0YV6"
      },
      "source": [
        "**Task 1:** Use the above `wrangle` function to import the `burritos.csv` file into a DataFrame named `df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHCfjRcqhDbs",
        "outputId": "2ee635f3-0f51-4423-e5da-7426f03d4c44"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegressionCV"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYvirniV0YV7"
      },
      "source": [
        "filepath = DATA_PATH + 'burritos/burritos.csv'\n",
        "df = wrangle(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJzYM0tu0YV7"
      },
      "source": [
        "During your exploratory data analysis, note that there are several columns whose data type is `object` but that seem to be a binary encoding. For example, `df['Beef'].head()` returns:\n",
        "\n",
        "```\n",
        "0      x\n",
        "1      x\n",
        "2    NaN\n",
        "3      x\n",
        "4      x\n",
        "Name: Beef, dtype: object\n",
        "```\n",
        "\n",
        "**Task 2:** Change the `wrangle` function so that these columns are properly encoded as `0` and `1`s. Be sure your code handles upper- and lowercase `X`s, and `NaN`s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaCu9A3J0YV7"
      },
      "source": [
        "# Conduct your exploratory data analysis here\n",
        "# And modify the `wrangle` function above."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bI9QM2h0YV8"
      },
      "source": [
        "If you explore the `'Burrito'` column of `df`, you'll notice that it's a high-cardinality categorical feature. You'll also notice that there's a lot of overlap between the categories. \n",
        "\n",
        "**Stretch Goal:** Change the `wrangle` function above so that it engineers four new features: `'california'`, `'asada'`, `'surf'`, and `'carnitas'`. Each row should have a `1` or `0` based on the text information in the `'Burrito'` column. For example, here's how the first 5 rows of the dataset would look.\n",
        "\n",
        "| **Burrito** | **california** | **asada** | **surf** | **carnitas** |\n",
        "| :---------- | :------------: | :-------: | :------: | :----------: |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "|  Carnitas   |       0        |     0     |    0     |      1       |\n",
        "| Carne asada |       0        |     1     |    0     |      0       |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "\n",
        "**Note:** Be sure to also drop the `'Burrito'` once you've engineered your new features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka_ngB8B0YV8"
      },
      "source": [
        "# Conduct your exploratory data analysis here\n",
        "# And modify the `wrangle` function above."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "-Kw02wn2ha99",
        "outputId": "dbbcc2b0-ebcb-433b-8361-1501285e0b0d"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Burrito</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-18</th>\n",
              "      <td>California</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>California</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>Carnitas</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>Carne asada</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-27</th>\n",
              "      <td>California</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-28</th>\n",
              "      <td>combo chicken</td>\n",
              "      <td>6.99</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-30</th>\n",
              "      <td>California</td>\n",
              "      <td>7.19</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-30</th>\n",
              "      <td>Carnitas</td>\n",
              "      <td>6.99</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-02-01</th>\n",
              "      <td>Monster California</td>\n",
              "      <td>9.25</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-02-06</th>\n",
              "      <td>Carne Asada</td>\n",
              "      <td>6.25</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Burrito  Cost  Hunger  ...  Sour cream  Pork  Great\n",
              "Date                                          ...                         \n",
              "2016-01-18         California   6.49     3.0  ...           0     0      0\n",
              "2016-01-24         California   5.45     3.5  ...           0     0      0\n",
              "2016-01-24            Carnitas  4.85     1.5  ...           0     1      0\n",
              "2016-01-24         Carne asada  5.25     2.0  ...           0     0      0\n",
              "2016-01-27          California  6.59     4.0  ...           0     0      1\n",
              "2016-01-28       combo chicken  6.99     4.0  ...           1     0      0\n",
              "2016-01-30          California  7.19     1.5  ...           1     0      0\n",
              "2016-01-30            Carnitas  6.99     4.0  ...           0     1      0\n",
              "2016-02-01  Monster California  9.25     3.5  ...           1     0      0\n",
              "2016-02-06         Carne Asada  6.25     3.5  ...           0     0      0\n",
              "\n",
              "[10 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPk_p6HZjvSG",
        "outputId": "db53f1ea-bb25-40bf-ff61-a0fd7b041057"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 421 entries, 2016-01-18 to 2019-08-27\n",
            "Data columns (total 23 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Burrito       421 non-null    object \n",
            " 1   Cost          414 non-null    float64\n",
            " 2   Hunger        418 non-null    float64\n",
            " 3   Length        283 non-null    float64\n",
            " 4   Circum        281 non-null    float64\n",
            " 5   Volume        281 non-null    float64\n",
            " 6   Tortilla      421 non-null    float64\n",
            " 7   Temp          401 non-null    float64\n",
            " 8   Meat          407 non-null    float64\n",
            " 9   Fillings      418 non-null    float64\n",
            " 10  Meat:filling  412 non-null    float64\n",
            " 11  Uniformity    419 non-null    float64\n",
            " 12  Salsa         396 non-null    float64\n",
            " 13  Synergy       419 non-null    float64\n",
            " 14  Wrap          418 non-null    float64\n",
            " 15  Beef          421 non-null    int64  \n",
            " 16  Pico          421 non-null    int64  \n",
            " 17  Guac          421 non-null    int64  \n",
            " 18  Cheese        421 non-null    int64  \n",
            " 19  Fries         421 non-null    int64  \n",
            " 20  Sour cream    421 non-null    int64  \n",
            " 21  Pork          421 non-null    int64  \n",
            " 22  Great         421 non-null    int64  \n",
            "dtypes: float64(14), int64(8), object(1)\n",
            "memory usage: 78.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuLMtEvDiATJ",
        "outputId": "632f73b3-25b2-440a-b889-a494830cf6f3"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Burrito           0\n",
              "Cost              7\n",
              "Hunger            3\n",
              "Length          138\n",
              "Circum          140\n",
              "Volume          140\n",
              "Tortilla          0\n",
              "Temp             20\n",
              "Meat             14\n",
              "Fillings          3\n",
              "Meat:filling      9\n",
              "Uniformity        2\n",
              "Salsa            25\n",
              "Synergy           2\n",
              "Wrap              3\n",
              "Beef              0\n",
              "Pico              0\n",
              "Guac              0\n",
              "Cheese            0\n",
              "Fries             0\n",
              "Sour cream        0\n",
              "Pork              0\n",
              "Great             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHptMNMMA42Q"
      },
      "source": [
        "df.dropna(subset = ['Reviewer'], inplace = True) # Drop 1 row where reviewer was NaN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_VtkWSfBOF7",
        "outputId": "ad3ed50f-617e-45da-c7de-071322003a09"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Burrito           0\n",
              "Cost              6\n",
              "Hunger            3\n",
              "Length          137\n",
              "Circum          139\n",
              "Volume          139\n",
              "Tortilla          0\n",
              "Temp             20\n",
              "Meat             13\n",
              "Fillings          3\n",
              "Meat:filling      8\n",
              "Uniformity        2\n",
              "Salsa            24\n",
              "Synergy           2\n",
              "Wrap              3\n",
              "Reviewer          0\n",
              "Beef              0\n",
              "Pico              0\n",
              "Guac              0\n",
              "Cheese            0\n",
              "Fries             0\n",
              "Sour cream        0\n",
              "Pork              0\n",
              "Great             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xqIuyCA0YV9"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 3:** Split your dataset into the feature matrix `X` and the target vector `y`. You want to predict `'Great'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1p11GtX0YV9"
      },
      "source": [
        "X = ['Cost',\t'Hunger',\t'Length',\t'Circum',\t'Volume',\t'Tortilla',\t'Temp',\t'Meat',\n",
        "     'Fillings',\t'Meat:filling',\t'Uniformity',\t'Salsa',\t'Synergy',\t'Wrap',\n",
        "     'Beef',\t'Pico',\t'Guac',\t'Cheese',\t'Fries',\t'Sour cream',\t'Pork']\n",
        "y = 'Great'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufFwqiCM0YV9"
      },
      "source": [
        "**Task 4:** Split `X` and `y` into a training set (`X_train`, `y_train`) and a test set (`X_test`, `y_test`).\n",
        "\n",
        "- Your training set should include data from 2016 through 2017. \n",
        "- Your test set should include data from 2018 and later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQT0IWTm0YV-"
      },
      "source": [
        "cutoff = pd.to_datetime('2018-01-01') # Create cutoff of January 1, 2018 for train/test split\n",
        "train = df[df.index < cutoff]\n",
        "test = df[df.index >= cutoff]\n",
        "\n",
        "X_train, y_train = train[X], train[y]\n",
        "X_test, y_test = test[X], test[y]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywzGtGsS96iz",
        "outputId": "d60ea8d5-fe7f-4b24-9039-be0149e56302"
      },
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((383, 21), (383,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbARDUMT-BKp",
        "outputId": "e12f2e34-5900-42c8-e516-7181023f5a6c"
      },
      "source": [
        "X_test.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((38, 21), (38,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADDYhj3J0YV-"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 5:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEJGznJi0YV-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7667baec-bced-4922-8fec-6ae2ea1e94d0"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "majority_class = y_train.mode()\n",
        "y_pred_baseline = [majority_class] * len(y_train)\n",
        "\n",
        "baseline_acc = accuracy_score(y_train, y_pred_baseline)\n",
        "print('Baseline Accuracy Score:', baseline_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline Accuracy Score: 0.5822454308093995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1aLdMGu0YV_"
      },
      "source": [
        "# IV. Build Model\n",
        "\n",
        "**Task 6:** Build a `Pipeline` named `model_logr`, and fit it to your training data. Your pipeline should include:\n",
        "\n",
        "- a `OneHotEncoder` transformer for categorical features, \n",
        "- a `SimpleImputer` transformer to deal with missing values, \n",
        "- a [`StandarScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) transfomer (which often improves performance in a logistic regression model), and \n",
        "- a `LogisticRegression` predictor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5uG0OnA0YV_"
      },
      "source": [
        "imputer = SimpleImputer()\n",
        "X_train_imputed = imputer.fit_transform(X_train) # Use SimpleImputer to impute mean for any remaining NaNs\n",
        "X_test_imputed = imputer.transform(X_test) # Use SimpleImputer to impute mean for any remaining NaNs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koHdPd4JF_2y"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed) # Use StandardScaler to standardize the features\n",
        "X_test_scaled = scaler.transform(X_test_imputed) # Use StandardScaler to standardize the features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LFp2cEAGmDY",
        "outputId": "a3b86d0b-367b-49bc-eb03-0a5eaea4f0ac"
      },
      "source": [
        "model_lr = LogisticRegressionCV()\n",
        "\n",
        "model_lr.fit(X_train_scaled, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
              "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
              "                     max_iter=100, multi_class='auto', n_jobs=None,\n",
              "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
              "                     solver='lbfgs', tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOu31jpz0YV_"
      },
      "source": [
        "# IV. Check Metrics\n",
        "\n",
        "**Task 7:** Calculate the training and test accuracy score for `model_lr`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo6xX5QC0YV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea73d06c-6ae1-4b0e-f632-d37454b1b87a"
      },
      "source": [
        "y_pred_train = model_lr.predict(X_train_scaled)\n",
        "y_pred_test = model_lr.predict(X_test_scaled)\n",
        "\n",
        "training_acc = accuracy_score(y_train, y_pred_train)\n",
        "test_acc = accuracy_score (y_test, y_pred_test)\n",
        "\n",
        "print('Training Accuracy Score:', training_acc)\n",
        "print('Test Accuracy Score:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy Score: 0.8955613577023499\n",
            "Test Accuracy Score: 0.7631578947368421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYaqz7Gc0YWA"
      },
      "source": [
        "# V. Communicate Results\n",
        "\n",
        "**Task 8:** Create a horizontal barchart that plots the 10 most important coefficients for `model_lr`, sorted by absolute value.\n",
        "\n",
        "**Note:** Since you created your model using a `Pipeline`, you'll need to use the [`named_steps`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) attribute to access the coefficients in your `LogisticRegression` predictor. Be sure to look at the shape of the coefficients array before you combine it with the feature names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRag7fLi0YWA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "cb15a9a4-422b-4f1a-870a-60061fdeae7d"
      },
      "source": [
        "# Create your horizontal barchart here.\n",
        "\n",
        "%matplotlib inline\n",
        "coefficients = pd.Series(model_lr.coef_[0], X_train.columns)\n",
        "coefficients.sort_values().plot.barh()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f00dc198b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvBVF1VP0YWB"
      },
      "source": [
        "There is more than one way to generate predictions with `model_lr`. For instance, you can use [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression) or [`predict_proba`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression#sklearn.linear_model.LogisticRegression.predict_proba).\n",
        "\n",
        "**Task 9:** Generate predictions for `X_test` using both `predict` and `predict_proba`. Then below, write a summary of the differences in the output for these two methods. You should answer the following questions:\n",
        "\n",
        "- What data type do `predict` and `predict_proba` output?\n",
        "- What are the shapes of their different output?\n",
        "- What numerical values are in the output?\n",
        "- What do those numerical values represent?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqYyqb0l0YWC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "734a32c6-569c-4c64-eb2a-2daf96457b6b"
      },
      "source": [
        "# Write code here to explore the differences between `predict` and `predict_proba`.\n",
        "\n",
        "y_pred_proba_test = model_lr.predict_proba(X_test_scaled)\n",
        "print(y_pred_proba_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.01246362 0.98753638]\n",
            " [0.07179909 0.92820091]\n",
            " [0.9704317  0.0295683 ]\n",
            " [0.00536791 0.99463209]\n",
            " [0.94794076 0.05205924]\n",
            " [0.68551104 0.31448896]\n",
            " [0.27661962 0.72338038]\n",
            " [0.03798138 0.96201862]\n",
            " [0.57668438 0.42331562]\n",
            " [0.20853289 0.79146711]\n",
            " [0.43322032 0.56677968]\n",
            " [0.83876951 0.16123049]\n",
            " [0.22659835 0.77340165]\n",
            " [0.48250185 0.51749815]\n",
            " [0.2661602  0.7338398 ]\n",
            " [0.26021391 0.73978609]\n",
            " [0.3168014  0.6831986 ]\n",
            " [0.93085733 0.06914267]\n",
            " [0.96771743 0.03228257]\n",
            " [0.9344884  0.0655116 ]\n",
            " [0.90730275 0.09269725]\n",
            " [0.13573878 0.86426122]\n",
            " [0.63796849 0.36203151]\n",
            " [0.52368207 0.47631793]\n",
            " [0.23879441 0.76120559]\n",
            " [0.74793043 0.25206957]\n",
            " [0.74421016 0.25578984]\n",
            " [0.00553367 0.99446633]\n",
            " [0.18711535 0.81288465]\n",
            " [0.0700199  0.9299801 ]\n",
            " [0.76837418 0.23162582]\n",
            " [0.30936177 0.69063823]\n",
            " [0.242581   0.757419  ]\n",
            " [0.88428736 0.11571264]\n",
            " [0.26723713 0.73276287]\n",
            " [0.49948203 0.50051797]\n",
            " [0.01760781 0.98239219]\n",
            " [0.15658662 0.84341338]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px5Agpw1H0W4",
        "outputId": "91e31209-9965-4fe3-a7bf-9ba3e0ed6280"
      },
      "source": [
        "print(y_pred_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 0 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0 1 1 1\n",
            " 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgpgzs3S0YWC"
      },
      "source": [
        "**Give your written answer here:**\n",
        "\n",
        "Both *predict* and *predict_proba* output a numpy array for the target based on the X_test data\n",
        "\n",
        "The shape of the *predict_proba* output is a two-element array for each element in the output. The shape of the *predict* output is an array with individual integer elements. \n",
        "\n",
        "The numerical values for the *predict* array are 0s and 1s. The numerical values for each element of the *predict_proba* array are floats which add to 1.\n",
        "\n",
        "The numerical values for the *predict* array represent whether that particular predicted target value is in one category or another (it is predicted to be 1 if the burrito is 'Great'; 0 if it is not). The numerical values for each element of the *predict_proba* array represent the probability as to whether that particular predicted target value is in one category or another (the first element is the probability that the burrito is not great; the second element is the probability that the burrito is 'Great').\n",
        "```\n",
        "\n",
        "\n",
        "```"
      ]
    }
  ]
}