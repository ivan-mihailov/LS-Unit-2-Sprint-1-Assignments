{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Ivan Mihailov LS_DS_214_solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivan-mihailov/LS-Unit-2-Sprint-1-Assignments/blob/main/Copy_of_Ivan_Mihailov_LS_DS_214_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaYlRc5g0YVr"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 1, Module 4*\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKnplpmf0YV2"
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "# If you're on Colab:\n",
        "if 'google.colab' in sys.modules:\n",
        "    DATA_PATH = 'https://raw.githubusercontent.com/LambdaSchool/DS-Unit-2-Linear-Models/master/data/'\n",
        "    !pip install category_encoders==2.*\n",
        "\n",
        "# If you're working locally:\n",
        "else:\n",
        "    DATA_PATH = '../data/'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsS9hU3h0YV4"
      },
      "source": [
        "# Module Project: Logistic Regression\n",
        "\n",
        "Do you like burritos? ðŸŒ¯ You're in luck then, because in this project you'll create a model to predict whether a burrito is `'Great'`.\n",
        "\n",
        "The dataset for this assignment comes from [Scott Cole](https://srcole.github.io/100burritos/), a San Diego-based data scientist and burrito enthusiast. \n",
        "\n",
        "## Directions\n",
        "\n",
        "The tasks for this project are the following:\n",
        "\n",
        "- **Task 1:** Import `csv` file using `wrangle` function.\n",
        "- **Task 2:** Conduct exploratory data analysis (EDA), and modify `wrangle` function .\n",
        "- **Task 3:** Split data into feature matrix `X` and target vector `y`.\n",
        "- **Task 4:** Split feature matrix `X` and target vector `y` into training and test sets.\n",
        "- **Task 5:** Establish the baseline accuracy score for your dataset.\n",
        "- **Task 6:** Build `model_logr` using a pipeline that includes three transfomers and `LogisticRegression` predictor. Train model on `X_train` and `X_test`.\n",
        "- **Task 7:** Calculate the training and test accuracy score for your model.\n",
        "- **Task 8:** Create a horizontal bar chart showing the 10 most influencial features for your  model. \n",
        "- **Task 9:** Demonstrate and explain the differences between `model_lr.predict()` and `model_lr.predict_proba()`.\n",
        "\n",
        "**Note** \n",
        "\n",
        "You should limit yourself to the following libraries:\n",
        "\n",
        "- `category_encoders`\n",
        "- `matplotlib`\n",
        "- `pandas`\n",
        "- `sklearn`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h7XHx7i0YV5"
      },
      "source": [
        "# I. Wrangle Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRVPfbi_0YV5"
      },
      "source": [
        "def wrangle(filepath):\n",
        "    # Import w/ DateTimeIndex\n",
        "    df = pd.read_csv(filepath, parse_dates=['Date'],\n",
        "                     index_col='Date')\n",
        "    \n",
        "    # Drop unrated burritos\n",
        "    df.dropna(subset=['overall'], inplace=True)\n",
        "    \n",
        "    # Derive binary classification target:\n",
        "    # We define a 'Great' burrito as having an\n",
        "    # overall rating of 4 or higher, on a 5 point scale\n",
        "    df['Great'] = (df['overall'] >= 4).astype(int)\n",
        "    \n",
        "    # Drop high cardinality categoricals\n",
        "    df = df.drop(columns=['Notes', 'Location', 'Address', 'URL', 'Neighborhood'])\n",
        "    \n",
        "    # Drop columns to prevent \"leakage\"\n",
        "    df = df.drop(columns=['Rec', 'overall'])\n",
        "\n",
        "    # Drop columns with too many NaNs\n",
        "    df = df.drop(columns=['Yelp', 'Google',\t'Chips', 'Mass (g)',\t'Density (g/mL)',\t\n",
        "                          'Unreliable',\t'NonSD',\t'Chicken',\t'Shrimp', 'Fish',\n",
        "                          'Rice',\t'Beans',\t'Lettuce',\t'Tomato', 'Bell peper',\t\n",
        "                          'Carrots', 'Cabbage',\t'Sauce',\t'Salsa.1','Cilantro',\t\n",
        "                          'Onion',\t'Taquito',\t'Pineapple',\t'Ham', 'Chile relleno',\n",
        "                          'Nopales',\t'Lobster',\t'Queso',\t'Egg', 'Mushroom',\n",
        "                          'Bacon',\t'Sushi',\t'Avocado',\t'Corn',\t'Zucchini', 'Reviewer'])\n",
        "    \n",
        "    # Replace 'x' and 'X' in ingredient columns with '1'\n",
        "\n",
        "    df['Beef'] = df['Beef'].replace(['x', 'X'], 1)\n",
        "    df['Pico'] = df['Pico'].replace(['x', 'X'], 1)\n",
        "    df['Guac'] = df['Guac'].replace(['x', 'X'], 1)\n",
        "    df['Cheese'] = df['Cheese'].replace(['x', 'X'], 1)\n",
        "    df['Fries'] = df['Fries'].replace(['x', 'X'], 1)\n",
        "    df['Sour cream'] = df['Sour cream'].replace(['x', 'X'], 1)\n",
        "    df['Pork'] = df['Pork'].replace(['x', 'X'], 1)\n",
        "\n",
        "    # Replace NaNs in ingredient columns with '0'\n",
        "\n",
        "    df['Beef'] = df['Beef'].fillna(0) \n",
        "    df['Pico'] = df['Pico'].fillna(0)\n",
        "    df['Guac'] = df['Guac'].fillna(0)\n",
        "    df['Cheese'] = df['Cheese'].fillna(0)\n",
        "    df['Fries'] = df['Fries'].fillna(0)\n",
        "    df['Sour cream'] = df['Sour cream'].fillna(0)\n",
        "    df['Pork'] = df['Pork'].fillna(0)\n",
        "\n",
        "    # Convert ingredient columns to integer\n",
        "\n",
        "    df['Beef'] = df['Beef'].astype(int)\n",
        "    df['Pico'] = df['Pico'].astype(int)\n",
        "    df['Guac'] = df['Guac'].astype(int)\n",
        "    df['Cheese'] = df['Cheese'].astype(int)\n",
        "    df['Fries'] = df['Fries'].astype(int)\n",
        "    df['Sour cream'] = df['Sour cream'].astype(int)\n",
        "    df['Pork'] = df['Pork'].astype(int)\n",
        "    \n",
        "    # Create a Nested Function to Clean the 'Burrito' Column for OneHotEncoding\n",
        "\n",
        "    def burrito_clean(x):\n",
        "      \n",
        "      # Locate 'California' or 'california' in row and replace entire value with 'california'\n",
        "      if (x.find('California') >= 0) | (x.find('california') >= 0):\n",
        "        y_final = x.replace(x, 'california')\n",
        "        return y_final\n",
        "      # Locate 'Asada' or 'asada' in row and replace entire value with 'asada'\n",
        "      elif (x.find('asada') >= 0) | (x.find('Asada') >= 0):\n",
        "        y_final = x.replace(x, 'asada')\n",
        "        return y_final\n",
        "      # Locate 'Carne' or 'carne' in row and replace entire value with 'asada'\n",
        "      elif (x.find('Carne') >= 0) | (x.find('carne') >= 0):\n",
        "        y_final = x.replace(x, 'asada')\n",
        "        return y_final\n",
        "      # Locate 'Surf' or 'surf' in row and replace entire value with 'surf'\n",
        "      elif (x.find('Surf') >= 0) | (x.find('surf') >= 0):\n",
        "        y_final = x.replace(x, 'surf')\n",
        "        return y_final\n",
        "      # Locate 'Turf' or 'turf' in row and replace entire value with 'surf'\n",
        "      elif (x.find('Turf') >= 0) | (x.find('turf') >= 0):\n",
        "        y_final = x.replace(x, 'surf')\n",
        "        return y_final\n",
        "      # Locate 'Carnitas' or 'carnitas' in row and replace entire value with 'carnitas'\n",
        "      elif (x.find('Carnitas') >= 0) | (x.find('carnitas') >= 0):\n",
        "        y_final = x.replace(x, 'carnitas')\n",
        "        return y_final\n",
        "      # Replace all other values with 'others'\n",
        "      else:\n",
        "        y_final = x.replace(x, 'others')\n",
        "        return y_final\n",
        "\n",
        "    # Apply burrito_clean nested function to 'Burrito' column\n",
        "\n",
        "    df['Burrito'] = df['Burrito'].apply(burrito_clean)\n",
        "\n",
        "    # OneHotEncode 'Burrito' column using Column Transformer\n",
        "\n",
        "    transformer = ColumnTransformer([('encoder', \n",
        "                                        ce.OneHotEncoder(use_cat_names = True), \n",
        "                                        [0])], \n",
        "                                      remainder='passthrough') \n",
        "  \n",
        "    df1 = transformer.fit_transform(df)\n",
        "    # Change df1 from a Numpy Array back to a Pandas Dataframe\n",
        "    df = pd.DataFrame(data=df1, index=df.index, columns=['Burrito_california',\n",
        "                                                         'Burrito_asada',\n",
        "                                                         'Burrito_surf',\n",
        "                                                         'Burrito_carnitas',\n",
        "                                                         'Burrito_others', 'Cost',\n",
        "                                                         'Hunger',\t'Length',\t\n",
        "                                                         'Circum',\t'Volume',\t\n",
        "                                                         'Tortilla',\t'Temp',\t\n",
        "                                                         'Meat',\t'Fillings',\t\n",
        "                                                         'Meat:filling',\t'Uniformity', \n",
        "                                                         'Salsa',\t'Synergy',\t\n",
        "                                                         'Wrap',\t'Beef',\t'Pico',\n",
        "                                                         'Guac',\t'Cheese',\t'Fries',\n",
        "                                                         'Sour cream',\t'Pork',\t'Great'])\n",
        "    \n",
        "    # Drop 'Burrito_others' column generated by OneHotEncoder\n",
        "\n",
        "    df = df.drop(columns='Burrito_others')\n",
        "\n",
        "    return df\n",
        "\n",
        "filepath = DATA_PATH + 'burritos/burritos.csv'"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_9VIkX-0YV6"
      },
      "source": [
        "**Task 1:** Use the above `wrangle` function to import the `burritos.csv` file into a DataFrame named `df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHCfjRcqhDbs"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.compose import ColumnTransformer"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYvirniV0YV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5faa004b-39fa-44af-b1b6-602601a9ecbf"
      },
      "source": [
        "filepath = DATA_PATH + 'burritos/burritos.csv'\n",
        "df = wrangle(filepath)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "jyzHezm8DdB9",
        "outputId": "9e4096a7-97cf-4e8a-9e9e-11c48b5ed705"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Burrito_california</th>\n",
              "      <th>Burrito_asada</th>\n",
              "      <th>Burrito_surf</th>\n",
              "      <th>Burrito_carnitas</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-18</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-27</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Burrito_california  Burrito_asada  ...  Pork  Great\n",
              "Date                                           ...             \n",
              "2016-01-18                 1.0            0.0  ...   0.0    0.0\n",
              "2016-01-24                 1.0            0.0  ...   0.0    0.0\n",
              "2016-01-24                 0.0            1.0  ...   1.0    0.0\n",
              "2016-01-24                 0.0            0.0  ...   0.0    0.0\n",
              "2016-01-27                 1.0            0.0  ...   0.0    1.0\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJzYM0tu0YV7"
      },
      "source": [
        "During your exploratory data analysis, note that there are several columns whose data type is `object` but that seem to be a binary encoding. For example, `df['Beef'].head()` returns:\n",
        "\n",
        "```\n",
        "0      x\n",
        "1      x\n",
        "2    NaN\n",
        "3      x\n",
        "4      x\n",
        "Name: Beef, dtype: object\n",
        "```\n",
        "\n",
        "**Task 2:** Change the `wrangle` function so that these columns are properly encoded as `0` and `1`s. Be sure your code handles upper- and lowercase `X`s, and `NaN`s."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaCu9A3J0YV7"
      },
      "source": [
        "# Conduct your exploratory data analysis here\n",
        "# And modify the `wrangle` function above."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhc1q6LUzLmH"
      },
      "source": [
        "def burrito_clean(x):\n",
        "  \n",
        "  if (x.find('california') >= 0) | (x.find('California') >= 0):\n",
        "    y_final = x.replace(x, 'california')\n",
        "  \n",
        "    return y_final\n",
        "  \n",
        "  elif (x.find('asada') >= 0) | (x.find('Asada') >= 0):\n",
        "    y_final = x.replace(x, 'asada')\n",
        "  \n",
        "    return y_final\n",
        "  \n",
        "  elif (x.find('carne') >= 0) | (x.find('Carne') >= 0):\n",
        "    y_final = x.replace(x, 'asada')\n",
        "  \n",
        "    return y_final\n",
        "\n",
        "  elif (x.find('surf') >= 0) | (x.find('Surf') >= 0):\n",
        "    y_final = x.replace(x, 'surf')\n",
        "  \n",
        "    return y_final\n",
        "\n",
        "  elif (x.find('turf') >= 0) | (x.find('Turf') >= 0):\n",
        "    y_final = x.replace(x, 'surf')\n",
        "  \n",
        "    return y_final\n",
        "\n",
        "  elif (x.find('carnitas') >= 0) | (x.find('Carnitas') >= 0):\n",
        "    y_final = x.replace(x, 'carnitas')\n",
        "  \n",
        "    return y_final\n",
        "\n",
        "  else:\n",
        "    y_final = x.replace(x, 'others')\n",
        "\n",
        "    return y_final"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBxH25phynIr",
        "outputId": "9a63e1b2-bb9c-4519-cc6d-2211f3130679"
      },
      "source": [
        "with pd.option_context('display.max_rows', 500): # Displays all of the values using value_counts\n",
        "    print (df['Burrito'].value_counts())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "California                        101\n",
            "Carne asada                        29\n",
            "California                         26\n",
            "Carnitas                           23\n",
            "Surf & Turf                        14\n",
            "Local                              14\n",
            "California Everything              13\n",
            "Al pastor                           9\n",
            "Adobada                             9\n",
            "Surfin California                   8\n",
            "Custom                              5\n",
            "Holy Moly                           5\n",
            "Carne asada everything              4\n",
            "California - Pork Adobada           3\n",
            "Chile Relleno                       3\n",
            "Pastor                              3\n",
            "Carne Asada                         3\n",
            "Fish                                3\n",
            "Breakfast                           3\n",
            "2 in 1                              3\n",
            "Pollo asado                         3\n",
            "Al Pastor                           3\n",
            "California everything               3\n",
            "Shrimp                              3\n",
            "Campeon                             2\n",
            "carne asada                         2\n",
            "California - Steak                  2\n",
            "Monster California                  2\n",
            "Mahi                                2\n",
            "Fusion                              2\n",
            "Asada                               2\n",
            "California chicken                  2\n",
            "Baja monster                        2\n",
            "Veggie                              2\n",
            "Hashbrown                           2\n",
            "TGunz                               2\n",
            "Bandido                             2\n",
            "La Paz                              2\n",
            "Chicken nopalito                    2\n",
            "Bacon breakfast                     2\n",
            "Chile verde pork                    2\n",
            "Bean and cheese                     2\n",
            "California - Chicken                2\n",
            "Chicken                             2\n",
            "California breakfast                1\n",
            "Chicken and rice                    1\n",
            "Surf and turf                       1\n",
            "Tijuana                             1\n",
            "Barbacoa                            1\n",
            "Cali Diablo                         1\n",
            "Vegetarian                          1\n",
            "Mauna Lani                          1\n",
            "California Burrito                  1\n",
            "Steak with guacamole                1\n",
            "Pollo adobado                       1\n",
            "Surf and turf                       1\n",
            "Azteca                              1\n",
            "Chile Verde (pork)                  1\n",
            "Pollo california                    1\n",
            "Quesa                               1\n",
            "Combo chicken                       1\n",
            "Veg Out                             1\n",
            "Lobster                             1\n",
            "Bean & cheese                       1\n",
            "Ala tingada california              1\n",
            "Al pastor tradicional               1\n",
            "Chimichanga beef                    1\n",
            "Oaxacalifornia                      1\n",
            "Pork california                     1\n",
            "Grilled fish salmon                 1\n",
            "California everything mini          1\n",
            "Ranchero steak                      1\n",
            "Carnitas                            1\n",
            "Bean and rice grande size           1\n",
            "Tilapia one                         1\n",
            "Tejano                              1\n",
            "Steak fajitas                       1\n",
            "Machaca                             1\n",
            "El Hawaiiano                        1\n",
            "Colimas burrito                     1\n",
            "Hot cheetos                         1\n",
            "combo chicken                       1\n",
            "California (only cheese)            1\n",
            "Bomb                                1\n",
            "Dave's California                   1\n",
            "Deborah's special                   1\n",
            "Surf and Turf                       1\n",
            "Al pastor                           1\n",
            "Quesaburro                          1\n",
            "Chile relleno and carnitas          1\n",
            "fried fish                          1\n",
            "Steak everything                    1\n",
            "Chicken avocado                     1\n",
            "Barbacoa                            1\n",
            "Spicy a la Diabla                   1\n",
            "carne asada                         1\n",
            "Cheese steak                        1\n",
            "Especial                            1\n",
            "California Chipotle                 1\n",
            "Adobado                             1\n",
            "Super                               1\n",
            "El Rusio                            1\n",
            "Hawaiian                            1\n",
            "Fajitas                             1\n",
            "Carne asada supreme                 1\n",
            "Alambre california                  1\n",
            "Philly                              1\n",
            "Pollo Asado                         1\n",
            "Shrimp california                   1\n",
            "Shrimp with guac                    1\n",
            "Bitchin California                  1\n",
            "California + Guac + sour cream      1\n",
            "California Surf                     1\n",
            "Supreme chicken                     1\n",
            "Arizona                             1\n",
            "Chicken asada                       1\n",
            "Shredded beef                       1\n",
            "Bean and Cheese                     1\n",
            "Adobada                             1\n",
            "Cabeza                              1\n",
            "California Surf and Turf            1\n",
            "619 Burrito Original                1\n",
            "Carne adobada                       1\n",
            "Nutty                               1\n",
            "battered fish                       1\n",
            "Mixed                               1\n",
            "Addiction                           1\n",
            "Pokirrito classic                   1\n",
            "Chicken Shawarma                    1\n",
            "Surfin california                   1\n",
            "Golden State                        1\n",
            "Ado-haba california                 1\n",
            "Name: Burrito, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REmM4_to1_Kq"
      },
      "source": [
        "df['Burrito'] = df['Burrito'].apply(burrito_clean)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di9aaFIH2QzL",
        "outputId": "cd809eb2-fc71-40b3-f803-aae6c462b1c1"
      },
      "source": [
        "df['Burrito'].value_counts()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "california    180\n",
              "others        155\n",
              "asada          44\n",
              "carnitas       25\n",
              "surf           17\n",
              "Name: Burrito, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bI9QM2h0YV8"
      },
      "source": [
        "If you explore the `'Burrito'` column of `df`, you'll notice that it's a high-cardinality categorical feature. You'll also notice that there's a lot of overlap between the categories. \n",
        "\n",
        "**Stretch Goal:** Change the `wrangle` function above so that it engineers four new features: `'california'`, `'asada'`, `'surf'`, and `'carnitas'`. Each row should have a `1` or `0` based on the text information in the `'Burrito'` column. For example, here's how the first 5 rows of the dataset would look.\n",
        "\n",
        "| **Burrito** | **california** | **asada** | **surf** | **carnitas** |\n",
        "| :---------- | :------------: | :-------: | :------: | :----------: |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "|  Carnitas   |       0        |     0     |    0     |      1       |\n",
        "| Carne asada |       0        |     1     |    0     |      0       |\n",
        "| California  |       1        |     0     |    0     |      0       |\n",
        "\n",
        "**Note:** Be sure to also drop the `'Burrito'` once you've engineered your new features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka_ngB8B0YV8"
      },
      "source": [
        "# Conduct your exploratory data analysis here\n",
        "# And modify the `wrangle` function above."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "-Kw02wn2ha99",
        "outputId": "0f0d48b8-c701-49fd-bc65-e93c505896c1"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Burrito_california</th>\n",
              "      <th>Burrito_asada</th>\n",
              "      <th>Burrito_surf</th>\n",
              "      <th>Burrito_carnitas</th>\n",
              "      <th>Cost</th>\n",
              "      <th>Hunger</th>\n",
              "      <th>Length</th>\n",
              "      <th>Circum</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Tortilla</th>\n",
              "      <th>Temp</th>\n",
              "      <th>Meat</th>\n",
              "      <th>Fillings</th>\n",
              "      <th>Meat:filling</th>\n",
              "      <th>Uniformity</th>\n",
              "      <th>Salsa</th>\n",
              "      <th>Synergy</th>\n",
              "      <th>Wrap</th>\n",
              "      <th>Beef</th>\n",
              "      <th>Pico</th>\n",
              "      <th>Guac</th>\n",
              "      <th>Cheese</th>\n",
              "      <th>Fries</th>\n",
              "      <th>Sour cream</th>\n",
              "      <th>Pork</th>\n",
              "      <th>Great</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2016-01-18</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.49</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.45</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.85</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-24</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.25</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-27</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.59</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-28</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.99</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-30</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7.19</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-01-30</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.99</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-02-01</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>9.25</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016-02-06</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.25</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>1.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Burrito_california  Burrito_asada  ...  Pork  Great\n",
              "Date                                           ...             \n",
              "2016-01-18                 1.0            0.0  ...   0.0    0.0\n",
              "2016-01-24                 1.0            0.0  ...   0.0    0.0\n",
              "2016-01-24                 0.0            1.0  ...   1.0    0.0\n",
              "2016-01-24                 0.0            0.0  ...   0.0    0.0\n",
              "2016-01-27                 1.0            0.0  ...   0.0    1.0\n",
              "2016-01-28                 0.0            0.0  ...   0.0    0.0\n",
              "2016-01-30                 1.0            0.0  ...   0.0    0.0\n",
              "2016-01-30                 0.0            1.0  ...   1.0    0.0\n",
              "2016-02-01                 1.0            0.0  ...   0.0    0.0\n",
              "2016-02-06                 0.0            0.0  ...   0.0    0.0\n",
              "\n",
              "[10 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPk_p6HZjvSG",
        "outputId": "e0d72061-c724-4066-a69b-85a779e831f7"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 421 entries, 2016-01-18 to 2019-08-27\n",
            "Data columns (total 26 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   Burrito_california  421 non-null    float64\n",
            " 1   Burrito_asada       421 non-null    float64\n",
            " 2   Burrito_surf        421 non-null    float64\n",
            " 3   Burrito_carnitas    421 non-null    float64\n",
            " 4   Cost                414 non-null    float64\n",
            " 5   Hunger              418 non-null    float64\n",
            " 6   Length              283 non-null    float64\n",
            " 7   Circum              281 non-null    float64\n",
            " 8   Volume              281 non-null    float64\n",
            " 9   Tortilla            421 non-null    float64\n",
            " 10  Temp                401 non-null    float64\n",
            " 11  Meat                407 non-null    float64\n",
            " 12  Fillings            418 non-null    float64\n",
            " 13  Meat:filling        412 non-null    float64\n",
            " 14  Uniformity          419 non-null    float64\n",
            " 15  Salsa               396 non-null    float64\n",
            " 16  Synergy             419 non-null    float64\n",
            " 17  Wrap                418 non-null    float64\n",
            " 18  Beef                421 non-null    float64\n",
            " 19  Pico                421 non-null    float64\n",
            " 20  Guac                421 non-null    float64\n",
            " 21  Cheese              421 non-null    float64\n",
            " 22  Fries               421 non-null    float64\n",
            " 23  Sour cream          421 non-null    float64\n",
            " 24  Pork                421 non-null    float64\n",
            " 25  Great               421 non-null    float64\n",
            "dtypes: float64(26)\n",
            "memory usage: 88.8 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuLMtEvDiATJ",
        "outputId": "632f73b3-25b2-440a-b889-a494830cf6f3"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Burrito           0\n",
              "Cost              7\n",
              "Hunger            3\n",
              "Length          138\n",
              "Circum          140\n",
              "Volume          140\n",
              "Tortilla          0\n",
              "Temp             20\n",
              "Meat             14\n",
              "Fillings          3\n",
              "Meat:filling      9\n",
              "Uniformity        2\n",
              "Salsa            25\n",
              "Synergy           2\n",
              "Wrap              3\n",
              "Beef              0\n",
              "Pico              0\n",
              "Guac              0\n",
              "Cheese            0\n",
              "Fries             0\n",
              "Sour cream        0\n",
              "Pork              0\n",
              "Great             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHptMNMMA42Q"
      },
      "source": [
        "df.dropna(subset = ['Reviewer'], inplace = True) # Drop 1 row where reviewer was NaN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_VtkWSfBOF7",
        "outputId": "ad3ed50f-617e-45da-c7de-071322003a09"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Burrito           0\n",
              "Cost              6\n",
              "Hunger            3\n",
              "Length          137\n",
              "Circum          139\n",
              "Volume          139\n",
              "Tortilla          0\n",
              "Temp             20\n",
              "Meat             13\n",
              "Fillings          3\n",
              "Meat:filling      8\n",
              "Uniformity        2\n",
              "Salsa            24\n",
              "Synergy           2\n",
              "Wrap              3\n",
              "Reviewer          0\n",
              "Beef              0\n",
              "Pico              0\n",
              "Guac              0\n",
              "Cheese            0\n",
              "Fries             0\n",
              "Sour cream        0\n",
              "Pork              0\n",
              "Great             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xqIuyCA0YV9"
      },
      "source": [
        "# II. Split Data\n",
        "\n",
        "**Task 3:** Split your dataset into the feature matrix `X` and the target vector `y`. You want to predict `'Great'`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1p11GtX0YV9"
      },
      "source": [
        "X = ['Burrito_california',\t'Burrito_asada',\t'Burrito_surf',\t'Burrito_carnitas',\n",
        "     'Cost',\t'Hunger',\t'Length',\t'Circum',\t'Volume',\t'Tortilla',\t'Temp',\t'Meat',\n",
        "     'Fillings',\t'Meat:filling',\t'Uniformity',\t'Salsa',\t'Synergy',\t'Wrap',\n",
        "     'Beef',\t'Pico',\t'Guac',\t'Cheese',\t'Fries',\t'Sour cream',\t'Pork']\n",
        "y = 'Great'"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufFwqiCM0YV9"
      },
      "source": [
        "**Task 4:** Split `X` and `y` into a training set (`X_train`, `y_train`) and a test set (`X_test`, `y_test`).\n",
        "\n",
        "- Your training set should include data from 2016 through 2017. \n",
        "- Your test set should include data from 2018 and later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQT0IWTm0YV-"
      },
      "source": [
        "cutoff = pd.to_datetime('2018-01-01') # Create cutoff of January 1, 2018 for train/test split\n",
        "train = df[df.index < cutoff]\n",
        "test = df[df.index >= cutoff]\n",
        "\n",
        "X_train, y_train = train[X], train[y]\n",
        "X_test, y_test = test[X], test[y]"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywzGtGsS96iz",
        "outputId": "af3ef2f3-d568-4bf9-ac8d-079013f937d5"
      },
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((383, 25), (383,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbARDUMT-BKp",
        "outputId": "14890f36-7daa-411b-e938-43814c4903d8"
      },
      "source": [
        "X_test.shape, y_test.shape"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((38, 25), (38,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADDYhj3J0YV-"
      },
      "source": [
        "# III. Establish Baseline\n",
        "\n",
        "**Task 5:** Since this is a **classification** problem, you should establish a baseline accuracy score. Figure out what is the majority class in `y_train` and what percentage of your training observations it represents. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEJGznJi0YV-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d97693-4729-47f7-dafc-a8ff5a7c4c18"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "majority_class = y_train.mode()\n",
        "y_pred_baseline = [majority_class] * len(y_train)\n",
        "\n",
        "baseline_acc = accuracy_score(y_train, y_pred_baseline)\n",
        "print('Baseline Accuracy Score:', baseline_acc)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline Accuracy Score: 0.5822454308093995\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1aLdMGu0YV_"
      },
      "source": [
        "# IV. Build Model\n",
        "\n",
        "**Task 6:** Build a `Pipeline` named `model_logr`, and fit it to your training data. Your pipeline should include:\n",
        "\n",
        "- a `OneHotEncoder` transformer for categorical features, \n",
        "- a `SimpleImputer` transformer to deal with missing values, \n",
        "- a [`StandarScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) transfomer (which often improves performance in a logistic regression model), and \n",
        "- a `LogisticRegression` predictor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5uG0OnA0YV_"
      },
      "source": [
        "imputer = SimpleImputer()\n",
        "X_train_imputed = imputer.fit_transform(X_train) # Use SimpleImputer to impute mean for any remaining NaNs\n",
        "X_test_imputed = imputer.transform(X_test) # Use SimpleImputer to impute mean for any remaining NaNs"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koHdPd4JF_2y"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_scaled = scaler.fit_transform(X_train_imputed) # Use StandardScaler to standardize the features\n",
        "X_test_scaled = scaler.transform(X_test_imputed) # Use StandardScaler to standardize the features"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LFp2cEAGmDY",
        "outputId": "014145fe-80ce-4b90-fa48-4e7a8c474702"
      },
      "source": [
        "model_lr = LogisticRegressionCV()\n",
        "\n",
        "model_lr.fit(X_train_scaled, y_train)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
              "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
              "                     max_iter=100, multi_class='auto', n_jobs=None,\n",
              "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
              "                     solver='lbfgs', tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOu31jpz0YV_"
      },
      "source": [
        "# IV. Check Metrics\n",
        "\n",
        "**Task 7:** Calculate the training and test accuracy score for `model_lr`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo6xX5QC0YV_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae825848-d4e0-4767-94f1-3ac24d2e7f70"
      },
      "source": [
        "y_pred_train = model_lr.predict(X_train_scaled)\n",
        "y_pred_test = model_lr.predict(X_test_scaled)\n",
        "\n",
        "training_acc = accuracy_score(y_train, y_pred_train)\n",
        "test_acc = accuracy_score (y_test, y_pred_test)\n",
        "\n",
        "print('Training Accuracy Score:', training_acc)\n",
        "print('Test Accuracy Score:', test_acc)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Accuracy Score: 0.9033942558746736\n",
            "Test Accuracy Score: 0.7631578947368421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYaqz7Gc0YWA"
      },
      "source": [
        "# V. Communicate Results\n",
        "\n",
        "**Task 8:** Create a horizontal barchart that plots the 10 most important coefficients for `model_lr`, sorted by absolute value.\n",
        "\n",
        "**Note:** Since you created your model using a `Pipeline`, you'll need to use the [`named_steps`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) attribute to access the coefficients in your `LogisticRegression` predictor. Be sure to look at the shape of the coefficients array before you combine it with the feature names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRag7fLi0YWA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "49c5a79d-0063-4a01-c30b-6eb9e2550e9a"
      },
      "source": [
        "# Create your horizontal barchart here.\n",
        "\n",
        "%matplotlib inline\n",
        "coefficients = pd.Series(model_lr.coef_[0], X_train.columns)\n",
        "coef_top_9 = coefficients.nlargest(9) # Isolate Top 9 features (by coefficient size)\n",
        "coef_bot_1 = coefficients.nsmallest(1) # Isolate Bottom 1 feature (by coefficient size)\n",
        "coef_top_10 = coef_top_9.append(coef_bot_1) # Append the Bottom 1 feature to the Top 9 features (by coefficient size)\n",
        "\n",
        "coef_top_10.sort_values().plot.barh()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f62775ad610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-yHGykjNGE4",
        "outputId": "6bc227ba-4fee-4c32-d82a-9b2d2888dcb7"
      },
      "source": [
        "coefficients.sort_values()"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pico                 -0.178766\n",
              "Burrito_carnitas     -0.122770\n",
              "Beef                 -0.097844\n",
              "Fries                -0.044746\n",
              "Cheese               -0.002653\n",
              "Wrap                 -0.001834\n",
              "Circum                0.000287\n",
              "Volume                0.001588\n",
              "Burrito_asada         0.002023\n",
              "Pork                  0.023594\n",
              "Burrito_surf          0.027777\n",
              "Sour cream            0.052722\n",
              "Hunger                0.073716\n",
              "Length                0.085728\n",
              "Guac                  0.148812\n",
              "Uniformity            0.152614\n",
              "Cost                  0.154865\n",
              "Burrito_california    0.160268\n",
              "Tortilla              0.273967\n",
              "Salsa                 0.281049\n",
              "Temp                  0.335564\n",
              "Meat:filling          0.516040\n",
              "Fillings              0.670461\n",
              "Meat                  0.678775\n",
              "Synergy               0.718770\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvBVF1VP0YWB"
      },
      "source": [
        "There is more than one way to generate predictions with `model_lr`. For instance, you can use [`predict`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression) or [`predict_proba`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logisticregression#sklearn.linear_model.LogisticRegression.predict_proba).\n",
        "\n",
        "**Task 9:** Generate predictions for `X_test` using both `predict` and `predict_proba`. Then below, write a summary of the differences in the output for these two methods. You should answer the following questions:\n",
        "\n",
        "- What data type do `predict` and `predict_proba` output?\n",
        "- What are the shapes of their different output?\n",
        "- What numerical values are in the output?\n",
        "- What do those numerical values represent?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqYyqb0l0YWC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b4e345-60e1-4ef6-d34b-177bb37e18b4"
      },
      "source": [
        "# Write code here to explore the differences between `predict` and `predict_proba`.\n",
        "\n",
        "y_pred_proba_test = model_lr.predict_proba(X_test_scaled)\n",
        "print(y_pred_proba_test)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.01133012 0.98866988]\n",
            " [0.05545975 0.94454025]\n",
            " [0.9791128  0.0208872 ]\n",
            " [0.00413463 0.99586537]\n",
            " [0.95482814 0.04517186]\n",
            " [0.67624474 0.32375526]\n",
            " [0.24574965 0.75425035]\n",
            " [0.03485274 0.96514726]\n",
            " [0.53660524 0.46339476]\n",
            " [0.18954336 0.81045664]\n",
            " [0.39322278 0.60677722]\n",
            " [0.85015789 0.14984211]\n",
            " [0.27573223 0.72426777]\n",
            " [0.45990815 0.54009185]\n",
            " [0.26613337 0.73386663]\n",
            " [0.20496615 0.79503385]\n",
            " [0.2515055  0.7484945 ]\n",
            " [0.90576665 0.09423335]\n",
            " [0.95454622 0.04545378]\n",
            " [0.913574   0.086426  ]\n",
            " [0.90627017 0.09372983]\n",
            " [0.13817984 0.86182016]\n",
            " [0.70044555 0.29955445]\n",
            " [0.57509599 0.42490401]\n",
            " [0.2942961  0.7057039 ]\n",
            " [0.79466153 0.20533847]\n",
            " [0.78561964 0.21438036]\n",
            " [0.00420556 0.99579444]\n",
            " [0.14459736 0.85540264]\n",
            " [0.08967363 0.91032637]\n",
            " [0.76041124 0.23958876]\n",
            " [0.36796538 0.63203462]\n",
            " [0.18539087 0.81460913]\n",
            " [0.90618963 0.09381037]\n",
            " [0.32562766 0.67437234]\n",
            " [0.41919175 0.58080825]\n",
            " [0.0226031  0.9773969 ]\n",
            " [0.19718749 0.80281251]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px5Agpw1H0W4",
        "outputId": "ff22dd28-e2cb-4699-cc35-475c1a489e8d"
      },
      "source": [
        "print(y_pred_test)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 1. 0. 0. 1. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgpgzs3S0YWC"
      },
      "source": [
        "**Give your written answer here:**\n",
        "\n",
        "Both *predict* and *predict_proba* output a numpy array for the target based on the X_test data\n",
        "\n",
        "The shape of the *predict_proba* output is a two-element array for each element in the output. The shape of the *predict* output is an array with individual integer elements. \n",
        "\n",
        "The numerical values for the *predict* array are 0s and 1s. The numerical values for each element of the *predict_proba* array are floats which add to 1.\n",
        "\n",
        "The numerical values for the *predict* array represent whether that particular predicted target value is in one category or another (it is predicted to be 1 if the burrito is 'Great'; 0 if it is not). The numerical values for each element of the *predict_proba* array represent the probability as to whether that particular predicted target value is in one category or another (the first element is the probability that the burrito is not great; the second element is the probability that the burrito is 'Great').\n",
        "```\n",
        "\n",
        "\n",
        "```"
      ]
    }
  ]
}